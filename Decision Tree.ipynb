{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees and Forests\n",
    "\n",
    "\n",
    "\n",
    "## Training a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data From CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>retire</th>\n",
       "      <th>gender</th>\n",
       "      <th>reside</th>\n",
       "      <th>custcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  tenure  age  marital  address  income  ed  employ  retire  gender  \\\n",
       "0       2      13   44        1        9    64.0   4       5     0.0       0   \n",
       "1       3      11   33        1        7   136.0   5       5     0.0       0   \n",
       "2       3      68   52        1       24   116.0   1      29     0.0       1   \n",
       "3       2      33   33        0       12    33.0   2       0     0.0       1   \n",
       "4       2      23   30        1        9    30.0   1       2     0.0       0   \n",
       "\n",
       "   reside  custcat  \n",
       "0       2        1  \n",
       "1       6        4  \n",
       "2       2        3  \n",
       "3       1        1  \n",
       "4       4        3  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('teleCust1000t.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization and Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    281\n",
       "1    266\n",
       "4    236\n",
       "2    217\n",
       "Name: custcat, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['custcat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define feature sets, X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['region', 'tenure', 'age', 'marital', 'address', 'income', 'ed',\n",
       "       'employ', 'retire', 'gender', 'reside', 'custcat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use scikit-learn library, we have to convert the Pandas data frame to a Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,  13.,  44.,   1.,   9.,  64.,   4.,   5.,   0.,   0.,   2.],\n",
       "       [  3.,  11.,  33.,   1.,   7., 136.,   5.,   5.,   0.,   0.,   6.],\n",
       "       [  3.,  68.,  52.,   1.,  24., 116.,   1.,  29.,   0.,   1.,   2.],\n",
       "       [  2.,  33.,  33.,   0.,  12.,  33.,   2.,   0.,   0.,   1.,   1.],\n",
       "       [  2.,  23.,  30.,   1.,   9.,  30.,   1.,   2.,   0.,   0.,   4.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['region', 'tenure','age', 'marital', 'address', 'income', 'ed', 'employ','retire', 'gender', 'reside']] .values  #.astype(float)\n",
    "X[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['custcat'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "Out of Sample Accuracy is the percentage of correct predictions that the model makes on data that that the model has NOT been trained on. Doing a train and test on the same dataset will most likely have low out-of-sample accuracy, due to the likelihood of being over-fit.\n",
    "\n",
    "It is important that our models have a high, out-of-sample accuracy, because the purpose of any model, of course, is to make correct predictions on unknown data. So how can we improve out-of-sample accuracy? One way is to use an evaluation approach called Train/Test Split. Train/Test Split involves splitting the dataset into training and testing sets respectively, which are mutually exclusive. After which, you train with the training set and test with the testing set.\n",
    "\n",
    "This will provide a more accurate evaluation on out-of-sample accuracy because the testing dataset is not part of the dataset that have been used to train the data. It is more realistic for real world problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (800, 11) (800,)\n",
      "Test set: (200, 11) (200,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.395\n",
      "Class Confusion Matrix\n",
      " [[30  6 10  5]\n",
      " [ 7 19  8 10]\n",
      " [15 14 17  8]\n",
      " [18  9 11 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "decisiontree = DecisionTreeClassifier(random_state=0)\n",
    "model = decisiontree.fit(X_train, y_train)\n",
    "\n",
    "target_predicted=model.predict(X_test)\n",
    "print(\"Accuracy\", model.score(X_test, y_test))\n",
    "\n",
    "matrix = confusion_matrix(y_test, target_predicted)\n",
    "print(\"Class Confusion Matrix\\n\", matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Decision tree learners attempt to find a decision rule that produces the greatest decrease in impurity at a node. While there are a number of measurements of impurity, by default `DecisionTreeClassifier` uses Gini impurity:\n",
    "$$\n",
    "G(t) = 1 - \\sum_{i=1}^c{p_i^2}\n",
    "$$\n",
    "where G(t) is the Gini impurity at node t and $p_i$ is the proportion of observations of class c at node t.\n",
    "\n",
    "This process of finding the decision rules that create splits to increase impurity is repeated recursively untill all leaf nodes are pure (i.e. contain only one class) or some abritary cut-off is reached\n",
    "\n",
    "We can change the `criterion` parameter to use a different impurity measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.335\n",
      "Class Confusion Matrix\n",
      " [[23  9 10  9]\n",
      " [13 12  7 12]\n",
      " [14 16 17  7]\n",
      " [12 12 12 15]]\n"
     ]
    }
   ],
   "source": [
    "# create decision tree classifier using entropy\n",
    "decisiontree_entropy = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "\n",
    "model_entropy = decisiontree_entropy.fit(X_train, y_train)\n",
    "\n",
    "target_predicted=model_entropy.predict(X_test)\n",
    "print(\"Accuracy\", model_entropy.score(X_test, y_test))\n",
    "\n",
    "matrix = confusion_matrix(y_test, target_predicted)\n",
    "print(\"Class Confusion Matrix\\n\", matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    counts = np.bincount(column)\n",
    "\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    entropy = 0\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy\n",
    "\n",
    "def calc_information_gain(data, split_name, target_name):\n",
    "\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    values = data[split_name].unique()\n",
    "    \n",
    "    \n",
    "    left_split = data[data[split_name] == values[0]]\n",
    "    right_split = data[data[split_name] == values[1]]\n",
    "    \n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    return original_entropy - to_subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['region', 'potato_salad?', 'sushi?']\n",
    "\n",
    "def highest_info_gain(columns):\n",
    "  information_gains = {}\n",
    "  \n",
    "  for col in columns:\n",
    "    information_gain = calc_information_gain(midwest, col, 'midwest?)                                       \n",
    "    information_gains[col] = information_gain\n",
    "                                        \n",
    "  return max(information_gains, key=information_gains.get)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your own code for decision tree by using Information Gain \n",
    "## Don't use ready code \n",
    "\n",
    "\n",
    "def calculate_column_IG(dataframe, column_name, class_label):\n",
    "\n",
    "    IG = 0 \n",
    "\n",
    "    if dataframe[column_name].dtypes != 'O':\n",
    "        print(\"1\");\n",
    "        raise Exception(\"Kategorik olmayan kolon goruldu.\")\n",
    "    else:\n",
    "        print(\"2\"); \n",
    "        kolonun_nunique_sayisi = dataframe[column_name].nunique()\n",
    "        \n",
    "        for j in range(kolonun_nunique_sayisi): \n",
    "            \n",
    "            if dataframe.isna().values.any(): \n",
    "                dataframe = dataframe.dropna() \n",
    "            else:\n",
    "                hesaplanmak_istenen_sutun = pd.DataFrame(dataframe.loc[dataframe[column_name] == dataframe.loc[:,column_name].unique()[j]][[column_name, class_label]])\n",
    "\n",
    "                vc_of_his = pd.DataFrame(hesaplanmak_istenen_sutun.value_counts())\n",
    "                \n",
    "                Entropy_of_his = entropy_calculate(hesaplanmak_istenen_sutun, hesaplanmak_istenen_sutun[class_label].name)\n",
    "                \n",
    "                level = dataframe.loc[:,column_name].unique()[j]\n",
    "                \n",
    "                SUM = vc_of_his.xs(level)[0].sum()\n",
    "                row_of_df = dataframe.shape[0]\n",
    "                \n",
    "                prob = SUM / row_of_df\n",
    "                \n",
    "                IG += (Entropy_of_his[-1] * prob)\n",
    "                \n",
    "                if j == kolonun_nunique_sayisi - 1:\n",
    "                    Information_Gain_List.append(IG)\n",
    "                    IG = 0 \n",
    "                    \n",
    "    return print(Information_Gain_List[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    i\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##  Visualizing a Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_29248/2741142556.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Abdullah\\AppData\\Local\\Temp/ipykernel_29248/2741142556.py\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    ....\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from IPython.display import Image\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "## Write your own code to visualize tree with 4 levels\n",
    "....\n",
    "....\n",
    "....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
